---
title: 对脑电信号的分类结果
date: 2019-04-08 10:08:12
categories:
- paper
tags:
- paper
- thinking
mathjax: true
---
这是记录我的脑电信号结果。
<!-- more -->
# 单通道
## 通道类型
Fc1
## 网络类型
CNN
### 网络结构
一共 4 层
#### 第一层
卷积层 size ：2 * 2 * 1 * 32 strides : 1,1,1,1
激活函数 relu
池化，最大池化 size : 1,2,2,1 strides : 1,2,2,1
#### 第二层
卷积层 size ：2 * 2 * 32 * 64 strides : 1,1,1,1
激活函数 relu
池化，最大池化 size : 1,2,2,1 strides : 1,2,2,1
#### 第三层
全连接层 [7*7*64,300]
激活函数 relu
#### 第四层
全连接层 [300,4]
激活函数 sigmoid
### loss
tf.nn.sparse_softmax_cross_entropy_with_logits
### 其它参数
研究对象:/pre/OC2ONE/S001.pkl，不包含 88，89，92，100 的
学习率 ： 0.0001
batch_size : 101
epoch : 300
是否随机： 是
train 数目 ： 17460
不足尺寸用自身补全
#### 结果
train acc | test acc
---|---|---
0.97020|  0.3035
0.94059|  0.3095
0.97029|  0.32738
0.91089|  0.30357
0.90099|  0.38690
### 其他参数
研究对象:/pre/OC2ONE/S001.pkl，不包含 88，89，92，100 的
学习率 ： 0.0002
batch_size : 101
epoch : 300
是否随机： 是
train 数目 ： 17460
不足尺寸用自身补全
#### 结果
train acc | test acc
---|---|---
0.94059|  0.32738
0.97029|  0.31547
0.95049|  0.30952
0.98019|  0.27380
0.95049|  0.30357
### 其他参数
研究对象:/pre/OC2ONE/S001.pkl，不包含 88，89，92，100 的
学习率 ： 0.01
batch_size : 101
epoch : 300
是否随机： 是
train 数目 ： 17460
不足尺寸用自身补全
#### 结果
train acc | test acc
---|---|---
0.23762|  0.25
0.15841|  0.25
### 其他参数
研究对象:/pre/OC2ONE/S001.pkl，不包含 88，89，92，100 的
学习率 ： 0.0001
batch_size : 101
epoch : 300
drop  : 0.5 对第一层全连接层进行 drop
是否随机： 是
train 数目 ： 17460
不足尺寸用自身补全
#### 结果
train acc | test acc
---|---|---
0.95049|  0.2559
0.94059|  0.27976
0.97029|  0.30357
### 其他参数
研究对象:/pre/OC2ONE/S001.pkl，不包含 88，89，92，100 的
学习率 ： 0.0001
batch_size : 101
epoch : 300
drop  : 0.5 对第一层全连接层进行 drop
是否随机： 是
train 数目 ： 17460
是否转化为IMG ： 是，size 2 * 2
不足尺寸用 0 补全
#### 结果
train acc | test acc
---|---|---
0.96039|  0.29166
0.95049|  0.32142
0.94059|  0.30952
### 其他参数
研究对象:/pre/OC2ONE/S001.pkl，不包含 88，89，92，100 的
学习率 ： 0.0001
batch_size : 101
epoch : 300
正则化，l2 ： 0.01 所有层的 w
是否随机： 是
train 数目 ： 17460
不足尺寸用自身补全
#### 结果
train acc | test acc
---|---|---
0.86138|  0.33928
0.75247|  0.34523
0.83168|  0.33928
0.90099|  0.28571
0.81188|  0.32142
### 其他参数
研究对象:/pre/OC2ONE/S001.pkl，不包含 88，89，92，100 的
学习率 ： 0.0001
batch_size : 101
epoch : 300
正则化，l2 ： 0.01 所有层的 w
drop  : 0.5 对第一层全连接层进行 drop
是否随机： 是
train 数目 ： 17460
不足尺寸用自身补全
#### 结果
train acc | test acc
---|---|---
0.58415|  0.33333
0.57425|  0.32142
0.58415|  0.32738
### 其他参数
研究对象:/pre/OC2ONE/S001.pkl，不包含 88，89，92，100 的
学习率 ： 0.0001
batch_size : 101
epoch : 300
正则化，l2 ： 0.01 所有层的 w
drop  : 0.5 对第一层全连接层进行 drop
是否随机： 是
train 数目 ： 17460
是否转化为IMG ： 是，size 2 * 2
不足尺寸用 0 补全
#### 结果
train acc | test acc
---|---|---
0.50495|  0.33333
0.59405|  0.34523
0.57425|  0.34523


## 网络类型
DNN
### 网络结构
一共 3 层
#### 第一层
连接层 [656,400]
激活函数 sigmoid
#### 第二层
连接层 [400,200]
激活函数 sigmoid
#### 第三层
连接层 [200,4]
激活函数 sigmoid
### loss
tf.nn.sparse_softmax_cross_entropy_with_logits
### 其他参数
研究对象:/pre/OC2ONE/S001.pkl，不包含 88，89，92，100 的
学习率 ： 0.0001
batch_size : 101
epoch : 300
是否随机： 是
train 数目 ： 17460
#### result
train acc | test acc
---|---|---
0.60396|  0.27380
0.62376|  0.27976
0.52475|  0.30357

### 其他参数
研究对象:/pre/OC2ONE/S001.pkl，不包含 88，89，92，100 的
学习率 ： 0.0001
batch_size : 101
epoch : 300
正则化，l2 ： 0.01 所有层的 w
drop ： 在倒数第一层和倒数第二层 0.5
是否随机： 是
train 数目 ： 17460
#### result
train acc | test acc
---|---|---
0.29709|  0.39285
0.39643|  0.39285

### 其他参数
研究对象:/pre/OC2ONE/S001.pkl，不包含 88，89，92，100 的
学习率 ： 0.0001
batch_size : 101
epoch : 300
正则化，l2 ： 0.0001 所有层的 w
是否随机： 是
train 数目 ： 17460
#### result
train acc | test acc
---|---|---
0.76237|  0.29761
0.43564|  0.26190
0.46534|  0.30357


### 其他参数
研究对象:/pre/OC2ONE/S001.pkl，不包含 88，89，92，100 的
学习率 ： 0.0001
batch_size : 101
epoch : 300
drop ： 在倒数第一层和倒数第二层 0.5
是否随机： 是
train 数目 ： 17460
#### result
train acc | test acc
---|---|---
0.47524|  0.33333
0.48514|  0.29761
0.46514|  0.31547



# 三通道
## 通道类型
Fc3 FcZ Fc4
## 网络类型
CNN
### 网络结构
一共 4 层
#### 第一层
卷积层 size ：3 * 3 * 3 * 32 strides : 1,1,1,1
激活函数 relu
池化，最大池化 size : 1,2,2,1 strides : 1,2,2,1
#### 第二层
卷积层 size ：3 * 3 * 32 * 64 strides : 1,1,1,1
激活函数 relu
池化，最大池化 size : 1,2,2,1 strides : 1,2,2,1
#### 第三层
全连接层 [7*7*64,300]
激活函数 relu
#### 第四层
全连接层 [300,4]
激活函数 sigmoid
### loss
tf.nn.sparse_softmax_cross_entropy_with_logits
### 其它参数
研究对象:/pre/OC135IMG/S001IMG.pkl，不包含 88，89，92，100 的
学习率 ： 0.0001
batch_size : 101
epoch : 300
是否随机： 是
train 数目 ： 17460
不足尺寸用自身补全
#### 结果
train acc | test acc
---|---|---
0.87128|  0.46428
0.95049|  0.5



