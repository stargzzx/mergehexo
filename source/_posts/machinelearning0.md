---
title: 权衡偏差和方差
date: 2018-06-16 12:46:52
categories:
- machine learning
tags:
- 偏差和方差
- machine learning
- math
- basis
---
这里说一下在机器学习中对于偏差和方差的理解。

<!-- more -->

## 数学定义

Generalization error又可以细分为Random Error、Bias和Variance三个部分。

首先需要说的是随机误差。它是数据本身的噪声带来的，这种误差是不可避免的。其次如果我们能够获得所有可能的数据集合，并在这个数据集合上将Loss最小化，这样学习到的模型就可以称之为“真实模型”，当然，我们是无论如何都不能获得并训练所有可能的数据的，所以真实模型一定存在，但无法获得，我们的最终目标就是去学习一个模型使其更加接近这个真实模型。

Bias和Variance分别从两个方面来描述了我们学习到的模型与真实模型之间的差距（除去随机误差）。

偏差：描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据，如下图第二行所示。

方差：描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散，如下图右列所示。

{% img /images/machinelearning/0_0.jpg %}

## 数学解释

排除人为的失误，人们一般会遇到三种误差来源：随机误差、偏差和方差。

首先需要说明的是随机误差。随机误差是数据本身的噪声带来的，这种误差是不可避免的。

一般认为随机误差服从高斯分布，记作ε N(0,σε)。

因此，若有变量y作为预测值，以及X作为自变量（协变量），那么我们将数据背后的真实规律f记作

{% img /images/machinelearning/0_1.JPG %}

## 形象说明

作者：刑无刀

[链接](https://www.zhihu.com/question/20448464/answer/24397161)

想象你开着一架黑鹰直升机，得到命令攻击地面上一只敌军部队，于是你连打数十梭子，结果有一下几种情况:

1.子弹基本上都打在队伍经过的一棵树上了，连在那棵树旁边等兔子的人都毫发无损，这就是方差小（子弹打得很集中），偏差大（跟目的相距甚远）。

2.子弹打在了树上，石头上，树旁边等兔子的人身上，花花草草也都中弹，但是敌军安然无恙，这就是方差大（子弹到处都是），偏差大（同1）。

3.子弹打死了一部分敌军，但是也打偏了些打到花花草草了，这就是方差大（子弹不集中），偏差小（已经在目标周围了）。

4.子弹一颗没浪费，每一颗都打死一个敌军，跟抗战剧里的八路军一样，这就是方差小（子弹全部都集中在一个位置），偏差小（子弹集中的位置正是它应该射向的位置）。方差，是形容数据分散程度的，算是“无监督的”，客观的指标，偏差，形容数据跟我们期望的中心差得有多远，算是“有监督的”，有人的知识参与的指标。

那么为什么偏差大方差就小，方差小偏差就大呢？

我们观看下图：

{% img /images/machinelearning/0_2.jpg %}

所谓的偏差就是模型对本训练集的拟合程度。

所谓的方差就是描述的是训练结果的分散程度。

以上图为例：

	1. 左上的模型偏差最大，右下的模型偏差最小；
	2. 左上的模型方差最小，右下的模型方差最大（因为那个是曲线所以结果很分散，所以方差大）。
	
## 机器学习中的表现

在统计学习框架下，大家刻画模型复杂度的时候，有这么个观点，认为Error = Bias +Variance。

这里的Error大概可以理解为模型的预测错误率，是有两部分组成的。

一部分是由于模型太简单而带来的估计不准确的部分——偏差（Bias）。

另一部分是由于模型太复杂而带来的更大的变化空间和不确定性——方差（Variance）。

要想在bias上表现好，low bias，就是复杂化模型，增加模型的参数，但这样容易过拟合 (overfitting)。

在一个实际系统中，Bias与Variance往往是不能兼得的。

如果要降低模型的Bias，就一定程度上会提高模型的Variance，反之亦然。

造成这种现象的根本原因是，我们总是希望试图用有限训练样本去估计无限的真实数据。

当我们更加相信这些数据的真实性，而忽视对模型的先验知识，就会尽量保证模型在训练样本上的准确度，这样可以减少模型的Bias。

但是，这样学习到的模型，很可能会失去一定的泛化能力，从而造成过拟合，降低模型在真实数据上的表现，增加模型的不确定性。

相反，如果更加相信我们对于模型的先验知识，在学习模型的过程中对模型增加更多的限制，就可以降低模型的variance，提高模型的稳定性，但也会使模型的Bias增大。

再看一个来自PRML的例子：

{% img /images/machinelearning/0_3.jpg %}

这是一个曲线拟合的问题，对同分布的不同数据集进行了多次的曲线拟合，左边表示方差（variance），右边表示偏差（bias），绿色是真实值函数。

lnλ 表示的是模型的复杂度，这个值越小，表示模型的复杂程度越高，在第一行，大家的复杂度都很低的时候，方差是很小的，但是偏差很大；

但是到了最后一幅图，我们可以得到，每个人的复杂程度都很高的情况下，不同的函数就有着天壤之别了，所以方差就很大，但此时偏差就很小了。

## 最佳平衡点

假设我们现在有一组训练数据，需要训练一个模型（基于梯度的学习）。

在训练的起始，Bias很大，因为我们的模型还没有来得及开始学习，也就是与“真实模型”差距很大。

然而此时variance却很小，因为训练数据集（training data）还没有来得及对模型产生影响，所以此时将模型应用于“不同的”训练数据集也不会有太大的差异。

而随着训练过程的进行，Bias变小了，因为我们的模型变得“聪明”了，懂得了更多关于“真实模型”的信息，输出值与真实值之间更加接近了。

但是如果我们训练得太久了，variance就会变得很大，因为我们除了学习到关于真实模型的信息，还学到了许多具体的，只针对我们使用的训练集（真实数据的子集）的信息。

而不同的可能的训练数据集（真实数据的子集）之间的某些特征和噪声是不一致的，这就导致了了我们在很多其他的数据集上就无法获得很好地效果，也就是所谓的Overfitting（过拟合）。

考虑到模型误差是偏差与方差的加和，因此我们可以绘制出这样的图像。

{% img /images/machinelearning/0_4.png %}

图中的最优位置，实际上是Total Error曲线的拐点。我们知道，连续函数的拐点意味着此处一阶导数的值为0。即

{% img /images/machinelearning/0_5.JPG %}

这个公式给出了寻找最优平衡点的数学描述。若模型复杂度小于平衡点，则模型的偏差会偏高，模型倾向于欠拟合；若模型复杂度大于平衡点，则模型的方差会偏高，模型倾向于过拟合。

## 过拟合与欠拟合的外在表现

尽管有了上述的数学表述，但是在现实环境中，有时候我们很难计算模型的偏差与方差。因此，我们需要通过外在表现，判断模型的拟合状态：是欠拟合还是过拟合。

同样地，在有限的训练数据集中，不断增加模型的复杂度，意味着模型会尽可能多地降低在训练集上的误差。因此在训练集上，不断地增加模型的复杂度，训练集上的误差会一直下降。

我们把数据分为三个部分：训练数据集、验证数据集、测试数据集。

因此，我们可以绘制出这样的图像。

{% img /images/machinelearning/0_6.png %}

在上图左边区域，训练集与验证集的误差都很高，这块区域的偏差比较高。

在右边区域，在验证集上误差很高，但是在训练集上偏差很低，这块区域的方差比较高。我们希望在中间的区域得到一个最优平衡点。

所以，偏差较高（欠拟合）有以下两个特征：

	1）训练集误差很高
	2）验证集误差和训练集误差差不多大

方差较高（过拟合）

	1）训练集误差较低
	2）非常高的验证集误差

##  如何处理欠拟合与过拟合

当模型处于欠拟合状态时，根本的办法是增加模型的复杂度。我们一般有以下一些办法：

	1）增加模型迭代次数；
	2）训练一个复杂度更高的模型：比如在神经网络中增加神经网络层数、在SVM中用非线性SVM（核技术）代替线性SVM
	3）获取更多的特征以供训练使用：特征少，对模型信息的刻画就不足够了
	4）降低正则化权重：正则化正是为了限制模型的灵活度（复杂度）而设定的，降低其权值可以在模型训练中增加模型复杂度。

当模型处于过拟合状态时，根本的办法是降低模型的复杂度。我们一般有以下一些办法：

	1）获取更多的数据：训练数据集和验证数据集是随机选取的，它们有不同的特征，以致在验证数据集上误差很高。更多的数据可以减小这种随机性的影响。
	2）减少特征数量
	3）增加正则化权重：方差很高时，模型对训练集的拟合很好。实际上，模型很有可能拟合了训练数据集的噪声，拿到验证集上拟合效果就不好了。我们可以增加正则化权重，减小模型的复杂度。


	
